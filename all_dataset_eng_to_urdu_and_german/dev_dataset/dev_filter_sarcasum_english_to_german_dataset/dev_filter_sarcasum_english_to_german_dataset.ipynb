{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnNo2mOKDtRI",
        "outputId": "8b020840-69bd-49ff-cf2f-36122128cb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is availble : ->  True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"GPU is availble : -> \" , torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "fZWVk-IxD7xC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline ko correct spelling se recreate karo\n",
        "# Load English to Urdu translator\n",
        "translator = pipeline(\n",
        "    \"translation\",\n",
        "    model=\"Helsinki-NLP/opus-mt-en-de\" , device = 0 # English ‚Üí Urdu ONLY\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFyj88uSD8Cy",
        "outputId": "d9a240fa-fc08-4352-b818-261228673a31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first data clean like remove symble which  not a text or also remove the space\n",
        "\n",
        "def clean_data(text):\n",
        " try:\n",
        "  if pd.isna(text) or text.strip() == '':\n",
        "    return ''\n",
        "  result = translator(str(text))\n",
        "  return result\n",
        " except Exception as e:\n",
        "  print(f\"some thing erong {e}\")\n",
        "  return e"
      ],
      "metadata": {
        "id": "CK8j881OD_FL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/dev_sarcasum_data.csv\")"
      ],
      "metadata": {
        "id": "_BeDxp9gD_Hw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYouhUuUD_KT",
        "outputId": "1fbd8edc-5363-4c43-9748-af65100bf3c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'binary', 'multiclass'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ouKRRZcD_M7",
        "outputId": "e54a57af-ddce-4ddb-b435-e3ffccfa905e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "252"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"dev_sarcasum_data.csv\"\n",
        "text = \"text\"\n",
        "dev_sarcasm_english_german = \"dev_sarcasm_english_german.csv\""
      ],
      "metadata": {
        "id": "haoA0wMlD_Ox"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i0c9yAoVRiLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_into_german = []\n",
        "total_text = len(df)\n",
        "batch_size = 50\n",
        "\n",
        "for i in range(0, total_text, batch_size):\n",
        "    batch_end = min(i + batch_size, total_text)\n",
        "    batch_text = df[\"text\"].iloc[i:batch_end].tolist()\n",
        "\n",
        "    batch_result_german = translator(\n",
        "        batch_text,\n",
        "        src_lang=\"en_XX\",    # English source\n",
        "        tgt_lang=\"de_DE\"     # ‚úÖ Correct Urdu code\n",
        "    )\n",
        "\n",
        "    print(f\"processing ......{i + 1} to .....{batch_end}\")\n",
        "\n",
        "    translated_texts = [result['translation_text'] for result in batch_result_german]\n",
        "    translate_into_german.extend(translated_texts)\n",
        "\n",
        "    progress = ((i + batch_size) / total_text) * 100\n",
        "    print(f\"‚úÖ Progress: {min(progress, 100):.1f}% complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuzSXaj2D_Qk",
        "outputId": "c75e43c8-491c-4eed-8c98-9ad65b974a5d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing ......1 to .....50\n",
            "‚úÖ Progress: 19.8% complete\n",
            "processing ......51 to .....100\n",
            "‚úÖ Progress: 39.7% complete\n",
            "processing ......101 to .....150\n",
            "‚úÖ Progress: 59.5% complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing ......151 to .....200\n",
            "‚úÖ Progress: 79.4% complete\n",
            "processing ......201 to .....250\n",
            "‚úÖ Progress: 99.2% complete\n",
            "processing ......251 to .....252\n",
            "‚úÖ Progress: 100.0% complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"translate_german\"] = translate_into_german\n",
        "file_save = [\"binary\" , \"multiclass\" , \"translate_german\"]\n",
        "print(f\"column save{file_save}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVSPLCMKD_Sf",
        "outputId": "955a3250-e69c-4f53-c979-4f0215218ad2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "column save['binary', 'multiclass', 'translate_german']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ew2O08VmD_bI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "final_csv_file = df[file_save].copy()  # Add ()\n",
        "final_csv_file.to_csv(dev_sarcasm_english_german, index=False)  # Fix False"
      ],
      "metadata": {
        "id": "ZQHmdQMDERdc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"üìÅ Output saved as: {dev_sarcasm_english_german}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds9yNSEDERfw",
        "outputId": "b430bbec-552f-40be-b2dd-7ca4df7aa972"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Output saved as: dev_sarcasm_english_german.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glH7d8mtERiX",
        "outputId": "2dcbca14-06dc-43e5-8ec8-3f5c06ed13f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing ......1 to .....50  (20%)\n",
            "processing ......51 to .....100  (40%)\n",
            "processing ......101 to .....150  (60%)\n",
            "processing ......151 to .....200  (79%)\n",
            "processing ......201 to .....250  (99%)\n",
            "processing ......251 to .....252  (100%)\n",
            "column save ['binary', 'multiclass', 'translate_german']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w3EMQrXYTdQh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}